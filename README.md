# Health risk prediction with imbalanced data
This paper compares the performance of classification and clustering techniques when applied to imbalanced data. 

# Abstract 
Time is an important variable in the treatment of many diseases. Owing the development of data mining techniques, the time to diagnosis can be shortened by using predictive models that identify individuals at risk in the early stages of disease development. In this logic, this paper found that Gradient Boost is powerful to deal with health data that are often imbalanced, with a weighted recall 0.95. Besides, unsupervised clustering has been applied to the same data with moderate results.  

# Data
The data from a fictional dataset built by UEA professor in order  . 
- For each record, the level of vulnerability to Vaerosa-19 is given by the variable target which takes the following values: low risk, moderate risk and high risk.
- 24 attributes in the database are processed with the aim of identifying which combination of variables is more effective in predicting an individual's vulnerability to Vaerosa-19 disease.
- 
# Methodology and key results

### Classification
Classification is a process that aims to label new data according to the patterns identified by the model in the training dataset. A wide variety of algorithms, with varying degrees of complexity, have been developed to facilitate this supervised learning. Each of these algorithms bases its operation on different set of criteria and follows a specific process to maximise the classification rate. The accuracy obtained at the end of the process partly depends on the data used. Thus, it is good practice to test different models and select the one that performs best for the project in question. Following this principle, we tested individual algorithms such as K Nearest Neighbours, Decision Tree and Naive Bayes and more complex models such as Neural Network. 
Each of the algorithms presented in the previous section went through a learning stage with the training data set and a prediction stage. Then, model tuning was used to find the hyperparameters that maximise model performance. To do so, different values for each of the given hyperparameters were compared using a grid search. Once the best parameters have been identified and integrated into each model, the classifiers are evaluated according to their comparative performance. The metrics used to assess performance include are balanced accuracy rate, precision, and recall. Precision refers to the ratio of instances correctly labelled for a given category to the total datapoints attributed to this class.  Recall gives the proportion of instances whose predicted label corresponds to the class to which they belong. Balanced accuracy rate gives the arithmetic average of proportion of prediction that are correctly made for each class. This metrics account for class imbalanced while assessing the overall performance of the model. The difference between the models is highlighted in the Table below. It can be seen that DT has the highest balanced score, followed by Support Vector Machine. At the bottom of the ranking, we have the Gaussian Naive Bayes model with a rate of 71.6%
Besides balanced accuracy rate, we can also compare the weighted recall since a good model should reach correctness of fit for the minority classes. Not only a good model should be able to correctly classify a large proportion of all the record, but also rightly allocate a large percentage of individual within each class. Correctly predict high or moderate vulnerability among people that belong to these classes might enable medical stakeholders to save more lives. DT reach a weighted recall of 0.94, which indicates that the model has correctly allocated the records of each classes. As displayed in the confusion matrix below, the high-risk class represents 8% of the test data and the different models label 4.55% to 7.7% as such. Regarding the other minority class, the individuals at moderate risk constitute 14% of the test data and the models correct classify 10.86 to 12.68% in this category. Considering the balanced accuracy and the recall for the high-risk class, Decision Tree appears to be the best model for this project. However, better performance can be achieved by combining the predictions obtained from each model. 

![My Image]([my-image.jpg](https://github.com/Kweshe/unbalanced_data/blob/main/comparison_table2.png))
__

Ensemble learners are models which can use multiple learning algorithms to perform better. Three Ensembles were tested to improve predictive performance for this dataset: Gradient Boosting Classifier, Random Forest and a voting classifier composed of the four best models from the previous section.  Both Random Forest and the voting system yielded an accuracy of 93.7%.  Gradient Boosting Classifier outperforms all the other algorithms with an accuracy rate of 94.6%, a balanced accuracy of 91%. More importantly, this model only misclassifies four instances of the high-risk class out of thirty-two. The model has precision of 97% for both low and high-risk class. The highest recall is that of the low-risk class (97%), followed by that of the moderate class which is 89%. High risk yielded a recall of 88%, which is mean that the model can identify an individual of that class with a probability of 0.88.   Even when the model is trained with unbalanced data, the accuracy rate increases slightly to 94.5%.  However, the recall for high-risk class is 0.81 with balanced data while it is 0.78 when resampling is not applied to the train data. Overall, the model performs well with both types of data. However, balancing improves the sensitivity of the model. 

The explanation behind the higher performance of Gradient Boosting is mechanism by which this algorithm operates. The Ensemble sequentially applies a basic classifier to repeatedly altered versions of the input in order to generate classifiers whose final class assignment is decided by weighted majority voting.  Thus, Boosting Gradient force the base classifier to focus more on data that weren't correctly identified in earlier rounds by giving them more weight. On the one hand we know that many models tend to misclassify minority classes, and on the other hand Gradient boost penalises that mis-classified more often during the training step. 

### ClusteringÂ 
The sub-sample that was used to validate the classification models was used to facilitate the comparative analysis. While looking for the optimal number of K that optimize the loss function for the K-prototype model, we found that three is a local minimum but is not the value that minimises the function over the entire interval. However, this value was used as the database has three labels. Moreover, we found that the hierarchical clustering reached a silhouette score of about 0.30 when the number of clusters is three.  
As suggested by the high accuracy rate, the classification obtained with Gradient Boosting is very similar to the true distribution of individuals between classes. The hierarchical clustering model has grouped most low and moderate risk individuals into a single cluster. At the bottom of the graph, a second cluster can be clearly identified which seems to correspond to the high- risk individuals. From the graph it is apparent that K-prototype put the high and moderate risk individuals in the same cluster. However, the model generated two other clusters each consisting mainly of instances of the majority class. 

The two models' performance was evaluated using three parameters: homogeneity, completeness and the Rand Index adjusted for chance (ARI). To compute this metrics, we use the true labels of the validation dataset. Prior to that, a ground truth was established with the DBSCAN algorithm. The homogeneity of the classification produced by agglomerative clustering is 0.12 while that of the other model is only 0.09. These figures are much lower than 1 and indicate a very high heterogeneity within each cluster in the sense that they each group together many individuals belonging to different classes. Regarding completeness, the hierarchical model reached a score of 0.26 while the K-prototype displays a score of 0.06. This shows that the former has a greater capacity to group the instances that belong to the same class in the same cluster. The Rand Index adjusted for chance (ARI) which measures the similarity between the clusters, takes value from zero to one. A value close to zero indicates that the clusters are very comparable in the clusters generated using an unsupervised method and the actual clusters. We obtain a score of 0.22 for the hierarchical clustering with complete linkage and a score of 0.03 with K-Prototype.  

The metrics would seem to suggest that the hierarchical is more effective at separating the data into clusters whereas the visualization of the clusters generated by the K-Prototype seems more informative. One possible explanation stems from the fact that the data is imbalanced. The first model grouped most instances into a single cluster. Which leads to a better completeness given that the majority of the datapoints belong to the low-risk class. Nevertheless, the separation made by K-Prototype seems to meet the objectives of the project. Indeed, separating low risk individuals from those facing a higher risk would allow medical actors to focus on the cluster that requires preventive or curative care. 
# Conclusion
This paper identity the best model to perform multi-class classification on an imbalanced dataset. The process has been undertaken following some major starting with transforming data into a format that is suitable for machine learning algorithms. Thereafter, we have resampled to correct data imbalance, perform features selection, model training and evaluation. We have found that the Ensemble Gradient Boost outperforms all the other algorithms tested. Furthermore, the data was clustered using Hierarchical clustering and K-Prototype. Despite the lower ARI, le dernier model seems to emulate more closely the behaviour of the original data. Overall, the project's findings suggest that classification is more effective than clustering at identifying subgroups with rare medical conditions. That is because, clustering is less complex and relies mainly on the similarity between the instances to build the clusters. At the opposite, classification models can learn from past data to increase their predictive power.   
